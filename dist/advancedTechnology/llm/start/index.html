<!doctype html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.18" /><meta name="theme" content="VuePress Theme Plume " /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><title>本地使用OLLAMA搭建大模型 | 作草分茶</title><meta name="description" content="作草分茶的生活和技术的记录"><link rel="preload" href="/assets/style-D8SJQLQ7.css" as="style"><link rel="stylesheet" href="/assets/style-D8SJQLQ7.css"><link rel="modulepreload" href="/assets/app-BZRVOKAf.js"><link rel="modulepreload" href="/assets/index.html-BWoHZ5KB.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-10308273><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0ea03461></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-0ea03461> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-10308273 data-v-52b8b9c2><div class="vp-navbar" vp-navbar data-v-52b8b9c2 data-v-06b854e9><div class="wrapper" data-v-06b854e9><div class="container" data-v-06b854e9><div class="title" data-v-06b854e9><div class="vp-navbar-title has-sidebar" data-v-06b854e9 data-v-37578852><a class="vp-link no-icon link title" href="/" data-v-37578852 data-v-92574703><!--[--><!--[--><!--]--><!----><span data-v-37578852>作草分茶</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-06b854e9><div class="content-body" data-v-06b854e9><!--[--><!--]--><div class="vp-navbar-search search" data-v-06b854e9><div class="search-wrapper" data-v-3902acc4><!----><div id="local-search" data-v-3902acc4><button type="button" class="mini-search mini-search-button" aria-label="Search" data-v-3902acc4><span class="mini-search-button-container"><svg class="mini-search-search-icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="mini-search-button-placeholder">Search</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-06b854e9 data-v-725f336b><span id="main-nav-aria-label" class="visually-hidden" data-v-725f336b>Main Navigation</span><!--[--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>首页</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/dev/soft-and-web/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>开发技术</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/java/toolUsage/79030a/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>Java</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/advancedTechnology/cloudNative/d3cfc7/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>前沿技术</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/linux/db53d7/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>Linux</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/middleware/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>中间件</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/note/systemArchitecture/hardware/" tabindex="0" data-v-725f336b data-v-7f0d67fb data-v-92574703><!--[--><!----><span data-v-7f0d67fb>学习笔记</span><!--]--><!----></a><!--]--><!--]--></nav><!----><div class="vp-navbar-appearance appearance" data-v-06b854e9 data-v-f835b784><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-f835b784 data-v-55afe581 data-v-a5a2da98><span class="check" data-v-a5a2da98><span class="icon" data-v-a5a2da98><!--[--><span class="vpi-sun sun" data-v-55afe581></span><span class="vpi-moon moon" data-v-55afe581></span><!--]--></span></span></button></div><!----><div class="vp-flyout vp-navbar-extra extra" data-v-06b854e9 data-v-bcfc2c7f data-v-1ca5f939><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-1ca5f939><span class="vpi-more-horizontal icon" data-v-1ca5f939></span></button><div class="menu" data-v-1ca5f939><div class="vp-menu" data-v-1ca5f939 data-v-c0f1acc0><!----><!--[--><!--[--><!----><div class="group" data-v-bcfc2c7f><div class="item appearance" data-v-bcfc2c7f><p class="label" data-v-bcfc2c7f>Appearance</p><div class="appearance-action" data-v-bcfc2c7f><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-bcfc2c7f data-v-55afe581 data-v-a5a2da98><span class="check" data-v-a5a2da98><span class="icon" data-v-a5a2da98><!--[--><span class="vpi-sun sun" data-v-55afe581></span><span class="vpi-moon moon" data-v-55afe581></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-06b854e9 data-v-9e2013c4><span class="container" data-v-9e2013c4><span class="top" data-v-9e2013c4></span><span class="middle" data-v-9e2013c4></span><span class="bottom" data-v-9e2013c4></span></span></button></div></div></div></div><div class="divider" data-v-06b854e9><div class="divider-line" data-v-06b854e9></div></div></div><!----></header><div class="vp-local-nav reached-top is-blog" data-v-10308273 data-v-1e249c68><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-1e249c68><span class="vpi-align-left menu-icon" data-v-1e249c68></span><span class="menu-text" data-v-1e249c68>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-1e249c68 data-v-ec1aef76><button data-v-ec1aef76>Return to top</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-10308273 data-v-5ffa159e><div class="curtain" data-v-5ffa159e></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-5ffa159e><span id="sidebar-aria-label" class="visually-hidden" data-v-5ffa159e> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-88ce4e2c><section class="vp-sidebar-item sidebar-item level-0 collapsible has-active" data-v-88ce4e2c data-v-44570768><div class="item" role="button" tabindex="0" data-v-44570768><div class="indicator" data-v-44570768></div><!----><h2 class="text" data-v-44570768>llm</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-44570768><span class="vpi-chevron-right caret-icon" data-v-44570768></span></div></div><div class="items" data-v-44570768><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/llm/start/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>本地使用OLLAMA搭建大模型</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-88ce4e2c><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-88ce4e2c data-v-44570768><div class="item" role="button" tabindex="0" data-v-44570768><div class="indicator" data-v-44570768></div><!----><h2 class="text" data-v-44570768>cloudNative</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-44570768><span class="vpi-chevron-right caret-icon" data-v-44570768></span></div></div><div class="items" data-v-44570768><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/d3cfc6/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>docker 基本使用</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/d3cfc7/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>docker 代理服务器配置</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/81e7b1/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>k8s 常用命令</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/db014d/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>k8s之Job与CronJob</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/dab1f6/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>Macos-minikube</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/517b0e/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>Ubuntu使用kubeadm安装k8s集群</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/cfd207/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>探索k8s过程中的问题和解决方案</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/104ac5/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>k8s持久化存储</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/23c98b/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>k8s 使用 StatefulSet 搭建 Redis 主从模式</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-44570768 data-v-44570768><div class="item" data-v-44570768><div class="indicator" data-v-44570768></div><!----><a class="vp-link no-icon link link" href="/advancedTechnology/cloudNative/104a10/" data-v-44570768 data-v-92574703><!--[--><p class="text" data-v-44570768>K8s部署单机Mysql</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-10308273 data-v-95f8217e><div class="has-sidebar has-aside vp-doc-container" data-v-9ceb7141><!--[--><!--]--><div class="container" data-v-9ceb7141><div class="aside" vp-outline data-v-9ceb7141><div class="aside-curtain" data-v-9ceb7141></div><div class="aside-container" data-v-9ceb7141><div class="aside-content" data-v-9ceb7141><div class="vp-doc-aside" data-v-9ceb7141 data-v-4f638d94><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-4f638d94 data-v-1f59b605><div class="content" data-v-1f59b605><div class="outline-marker" data-v-1f59b605></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-1f59b605><span data-v-1f59b605>On this page</span><span class="vpi-print icon" data-v-1f59b605></span></div><ul class="root" data-v-1f59b605 data-v-61e9c594><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-4f638d94></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-9ceb7141><div class="content-container" data-v-9ceb7141><!--[--><!--]--><main class="main" data-v-9ceb7141><nav class="vp-breadcrumb" data-v-9ceb7141 data-v-69e0b9e4><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-69e0b9e4><!--[--><li property="itemListElement" typeof="ListItem" data-v-69e0b9e4><a class="vp-link no-icon link breadcrumb" href="/" property="item" typeof="WebPage" data-v-69e0b9e4 data-v-92574703><!--[-->Home<!--]--><!----></a><span class="vpi-chevron-right" data-v-69e0b9e4></span><meta property="name" content="Home" data-v-69e0b9e4><meta property="position" content="1" data-v-69e0b9e4></li><li property="itemListElement" typeof="ListItem" data-v-69e0b9e4><span class="vp-link no-icon breadcrumb" href="/" property="item" typeof="WebPage" data-v-69e0b9e4 data-v-92574703><!--[-->llm<!--]--><!----></span><span class="vpi-chevron-right" data-v-69e0b9e4></span><meta property="name" content="llm" data-v-69e0b9e4><meta property="position" content="2" data-v-69e0b9e4></li><li property="itemListElement" typeof="ListItem" data-v-69e0b9e4><a class="vp-link no-icon link breadcrumb current" href="/advancedTechnology/llm/start/" property="item" typeof="WebPage" data-v-69e0b9e4 data-v-92574703><!--[-->本地使用OLLAMA搭建大模型<!--]--><!----></a><!----><meta property="name" content="本地使用OLLAMA搭建大模型" data-v-69e0b9e4><meta property="position" content="3" data-v-69e0b9e4></li><!--]--></ol></nav><!--[--><h1 class="vp-doc-title page-title" data-v-ea202df4>本地使用OLLAMA搭建大模型 <!----></h1><div class="vp-doc-meta" data-v-ea202df4><p class="reading-time" data-v-ea202df4><span class="vpi-books icon" data-v-ea202df4></span><span data-v-ea202df4>About 1854 words</span><span data-v-ea202df4>About 6 min</span></p><!----><p class="create-time" data-v-ea202df4><span class="vpi-clock icon" data-v-ea202df4></span><span data-v-ea202df4>2024-06-09</span></p></div><!--]--><div class="_advancedTechnology_llm_start_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-9ceb7141><div data-v-9ceb7141><h2 id="什么是大模型" tabindex="-1"><a class="header-anchor" href="#什么是大模型"><span>什么是大模型</span></a></h2><p>大模型（Large Model）通常指的是由大量参数组成的机器学习模型，特别是在自然语言处理（NLP）领域，通常指的是基于深度学习的神经网络模型，如GPT（Generative Pre-trained Transformer）系列。以下是大模型的一些关键特点和内容：</p><h3 id="特点" tabindex="-1"><a class="header-anchor" href="#特点"><span>特点</span></a></h3><ol><li><p><strong>大量参数</strong>：大模型通常包含数亿到数千亿个参数。这些参数通过大规模的数据集训练，使模型能够捕捉和生成复杂的语言模式和结构。</p></li><li><p><strong>强大的语言理解和生成能力</strong>：大模型在处理各种语言任务时表现出色，如文本生成、翻译、摘要、问答等。</p></li><li><p><strong>预训练和微调</strong>：大模型一般先通过海量文本数据进行预训练，学习广泛的语言知识和模式，然后通过微调（fine-tuning）在特定任务或领域数据上进一步优化。</p></li><li><p><strong>多功能性</strong>：大模型可以用于多种任务，不需要为每个任务单独训练一个新模型，只需通过调整提示词或微调即可适应新任务。</p></li></ol><h3 id="发展历程" tabindex="-1"><a class="header-anchor" href="#发展历程"><span>发展历程</span></a></h3><ol><li><p><strong>早期模型</strong>：早期的语言模型，如Word2Vec和GloVe，主要关注词向量的表示。</p></li><li><p><strong>Transformer架构</strong>：Transformer模型的引入是一个重大突破。它利用自注意力机制，能够更好地捕捉文本中的长距离依赖关系。</p></li><li><p><strong>GPT系列</strong>：</p><ul><li>GPT-1：OpenAI发布的第一个GPT模型，展示了通过预训练和微调进行文本生成的潜力。</li><li>GPT-2：扩展了模型的规模和训练数据量，显著提升了生成文本的质量。</li><li>GPT-3：包含1750亿个参数，大幅提升了模型的生成能力和多功能性。</li><li>GPT-4：进一步扩展了参数规模和训练数据，增强了模型在多任务处理中的表现。</li></ul></li></ol><h3 id="应用领域" tabindex="-1"><a class="header-anchor" href="#应用领域"><span>应用领域</span></a></h3><ol><li><p><strong>自然语言处理</strong>：文本生成、翻译、摘要、情感分析等。</p></li><li><p><strong>对话系统</strong>：聊天机器人、虚拟助手、客户服务等。</p></li><li><p><strong>创意写作</strong>：文章、故事、剧本生成等。</p></li><li><p><strong>教育和研究</strong>：提供知识问答、辅助写作、语言学习等。</p></li><li><p><strong>商业和营销</strong>：文案撰写、个性化推荐、数据分析等。</p></li></ol><h3 id="挑战和问题" tabindex="-1"><a class="header-anchor" href="#挑战和问题"><span>挑战和问题</span></a></h3><ol><li><p><strong>计算资源需求</strong>：大模型的训练和推理需要大量的计算资源和时间。</p></li><li><p><strong>数据隐私和安全</strong>：使用大规模数据进行训练可能涉及隐私和数据安全问题。</p></li><li><p><strong>模型偏见</strong>：训练数据中的偏见可能导致模型输出结果中存在偏见。</p></li><li><p><strong>可解释性</strong>：大模型的决策过程复杂，难以解释其生成的具体原因和逻辑。</p></li></ol><h3 id="未来发展" tabindex="-1"><a class="header-anchor" href="#未来发展"><span>未来发展</span></a></h3><ol><li><p><strong>模型压缩和优化</strong>：研究如何在保持性能的前提下降低模型规模和计算需求。</p></li><li><p><strong>更好的训练数据和方法</strong>：提高数据质量，改进训练方法，减少偏见和提高模型的鲁棒性。</p></li><li><p><strong>多模态模型</strong>：结合文本、图像、音频等多种数据类型，提升模型的综合理解和生成能力。</p></li></ol><p>通过了解大模型的特点、应用和挑战，可以更好地利用这些先进的技术，实现各种实际应用中的创新和改进。</p><h2 id="使用-ollama-搭建大模型" tabindex="-1"><a class="header-anchor" href="#使用-ollama-搭建大模型"><span>使用 OLLAMA 搭建大模型</span></a></h2><h3 id="环境准备" tabindex="-1"><a class="header-anchor" href="#环境准备"><span>环境准备</span></a></h3><ol><li>有一台性能不差的电脑，OLLAMA 推荐配置如下，至少需要 8G 的 RAM： <img src="https://qiqiang.oss-cn-hangzhou.aliyuncs.com/muan/ZMyLFo.png" alt="ZMyLFo"></li><li>准备 docker 环境，可参考教程 <a href="/advancedTechnology/cloudNative/d3cfc6">docker基本使用</a>；</li></ol><h3 id="搭建-ollama" tabindex="-1"><a class="header-anchor" href="#搭建-ollama"><span>搭建 OLLAMA</span></a></h3><p><a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">ollama 官方网站</a></p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>https://ollama.com</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><a href="https://hub.docker.com/r/ollama/ollama" target="_blank" rel="noopener noreferrer">ollama docker 网站</a></p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>https://hub.docker.com/r/ollama/ollama</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>使用 docker 安装 OLLAMA</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">docker</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> run</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -d</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -v</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ~/.ollama:/root/.ollama</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -p</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 11434:11434</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --name</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama/ollama</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Unable</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> to</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> find</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> image</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">ollama/ollama:latest</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> locally</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">latest:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> Pulling</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> from</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama/ollama</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">a8b1c5f80c2d:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> Pull</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> complete</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">7110e83425ad:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> Pull</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> complete</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">d73d7155397d:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> Pull</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> complete</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Digest:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> sha256:6363c5da064b02b5a1d15dbd1205c652e01c0e57accbfd831115e35a3efe0572</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Status:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> Downloaded</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> newer</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> image</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> for</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama/ollama:latest</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">8eb905b0e7b0bba918095d2c5eed669bda3b9d67ac947c77eef18ceae475ed0f</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>因为基础模型镜像比较大，所以建议使用挂载卷的方式将 OLLAMA 下载的模型挂载到宿主机的<code>~/.ollama</code>目录下，这样后面多次折腾下载数据会快一些。</p><p>启动完成之后，可以在浏览器打开<code>http://127.0.0.1:11434</code>，或者在终端输入</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">curl</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> http://127.0.0.1:11434</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> is</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> running</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到 OLLAMA 启动成功了。</p><p>也可以查看本机的局域网 IP 是多少，方便后面部署 Open-WebUI 使用。</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">ifconfig</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">|</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">grep</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">	inet</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192.168.1.3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> netmask</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 0xffffff00</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> broadcast</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192.168.1.255</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">	inet</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192.168.31.62</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> netmask</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 0xffffff00</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> broadcast</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192.168.31.255</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">	inet</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192.168.64.1</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> netmask</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 0xffffff00</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> broadcast</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 192.168.64.255</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">curl</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> http://192.168.1.3:11434</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> is</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> running</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="运行大模型" tabindex="-1"><a class="header-anchor" href="#运行大模型"><span>运行大模型</span></a></h3><p>进入 Docker 容器内部</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>docker exec -it ollama bash</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>打开 <a href="https://ollama.com/search?q=&amp;p=1&amp;sort=popular" target="_blank" rel="noopener noreferrer">ollama 网站</a>搜索需要运行的大模型，我们已 llama3 为例，进行下载。</p><p><img src="https://qiqiang.oss-cn-hangzhou.aliyuncs.com/muan/vqDuIr.png" alt="vqDuIr"></p><p>复制命令<code>ollama run llama3</code>，也可以根据配置下载不同参数的大模型。</p><p>下载过程需要一些时间，毕竟文件还是挺大的，大模型参数越大，镜像越大。</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>ollama run llama3</span></span>
<span class="line"><span>pulling manifest</span></span>
<span class="line"><span>pulling 6a0746a1ec1a... 100% ▕██████████████████████████████████████████████████████████▏ 4.7 GB</span></span>
<span class="line"><span>pulling 4fa551d4f938... 100% ▕██████████████████████████████████████████████████████████▏  12 KB</span></span>
<span class="line"><span>pulling 8ab4849b038c... 100% ▕██████████████████████████████████████████████████████████▏  254 B</span></span>
<span class="line"><span>pulling 577073ffcc6c... 100% ▕██████████████████████████████████████████████████████████▏  110 B</span></span>
<span class="line"><span>pulling 3f8eb4da87fa... 100% ▕██████████████████████████████████████████████████████████▏  485 B</span></span>
<span class="line"><span>verifying sha256 digest</span></span>
<span class="line"><span>writing manifest</span></span>
<span class="line"><span>removing any unused layers</span></span>
<span class="line"><span>success</span></span>
<span class="line"><span>&gt;&gt;&gt; Send a message (/? for help)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>此时就可以和 llama3 聊天了。</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>&gt;&gt;&gt; 你是谁</span></span>
<span class="line"><span>I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational</span></span>
<span class="line"><span>manner. I&#39;m not a human, but a computer program designed to simulate conversation and answer questions to the best</span></span>
<span class="line"><span>of my ability based on my training data. I can generate human-like text responses to your questions or prompts, and</span></span>
<span class="line"><span>engage in natural-sounding conversations. My primary function is to assist users with information and tasks, and to</span></span>
<span class="line"><span>provide helpful and accurate responses. I&#39;m constantly learning and improving, so please bear with me if I make any</span></span>
<span class="line"><span>mistakes or don&#39;t fully understand what you&#39;re asking. 😊</span></span>
<span class="line"><span></span></span>
<span class="line"><span>&gt;&gt;&gt; 可以用中文和我聊天吗</span></span>
<span class="line"><span>😊</span></span>
<span class="line"><span></span></span>
<span class="line"><span>可以！我也能使用中文与你聊天。请随时提出你的问题或想法，我将尽力回答和讨论。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>（Note: Although I&#39;m capable of understanding and responding in Chinese, my proficiency may vary depending on the</span></span>
<span class="line"><span>complexity and nuance of the topic. If you&#39;re unsure about something or want me to clarify a point, please don&#39;t</span></span>
<span class="line"><span>hesitate to ask!）</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到，llama3 对中文并不是很熟悉，有兴趣的同学可以使用阿里巴巴开源的千问2大模型（qwen2）。</p><h3 id="搭建-open-webui" tabindex="-1"><a class="header-anchor" href="#搭建-open-webui"><span>搭建 Open-WebUI</span></a></h3><p><a href="https://openwebui.com/" target="_blank" rel="noopener noreferrer">Open-WebUI 官方网站</a></p><p><a href="https://github.com/open-webui/open-webui#troubleshooting" target="_blank" rel="noopener noreferrer">Open-WebUI Github</a></p><p>在终端执行命令</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">docker</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> run</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -d</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -p</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 3000:8080</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -v</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ~/.open-webui:/app/backend/data</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --name</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> open-webui</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --restart</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> always</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ghcr.io/open-webui/open-webui:main</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">128ae8d335f61476d51f40d1f3bc88e9ae2b136cfd7a5fae0e42412e254f7f3c</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>浏览器打开<code>http://localhost:3000</code>，会进入登录界面，此时需要注册一个账号，第一个注册的账号是管理员账号。</p><p>看下提问面板</p><p><img src="https://qiqiang.oss-cn-hangzhou.aliyuncs.com/muan/LLnH8i.png" alt="LLnH8i"></p><h3 id="搭建-maxkb" tabindex="-1"><a class="header-anchor" href="#搭建-maxkb"><span>搭建 MaxKB</span></a></h3><p>MaxKB 是一款基于 LLM 大语言模型的知识库问答系统。MaxKB = Max Knowledge Base，旨在成为企业的最强大脑。</p><p>开箱即用：支持直接上传文档、自动爬取在线文档，支持文本自动拆分、向量化、RAG（检索增强生成），智能问答交互体验好； 无缝嵌入：支持零编码快速嵌入到第三方业务系统； 多模型支持：支持对接主流的大模型，包括 Ollama 本地私有大模型（如 Meta Llama 3、qwen 等）、通义千问、OpenAI、Azure OpenAI、Kimi、智谱 AI、讯飞星火和百度千帆大模型等。</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">docker</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> run</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -d</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --name=maxkb</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -p</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 8081:8080</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -v</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ~/.maxkb:/var/lib/postgresql/data</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 1panel/maxkb</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-9ceb7141 data-v-7ff12213><!--[--><!--]--><!----><div class="contributors" aria-label="Contributors" data-v-7ff12213><span class="contributors-label" data-v-7ff12213>Contributors: </span><span class="contributors-info" data-v-7ff12213><!--[--><!--[--><span class="contributor" data-v-7ff12213>qiqiang</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" data-v-7ff12213>Quince</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-7ff12213><div class="pager" data-v-7ff12213><!----></div><div class="pager" data-v-7ff12213><a class="vp-link no-icon link pager-link next" href="/advancedTechnology/cloudNative/d3cfc6/" data-v-7ff12213 data-v-92574703><!--[--><span class="desc" data-v-7ff12213>Next page</span><span class="title" data-v-7ff12213>docker 基本使用</span><!--]--><!----></a></div></nav></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-10308273 data-v-40f0a6f0><span class="percent" data-allow-mismatch data-v-40f0a6f0>0%</span><span class="show icon vpi-back-to-top" data-v-40f0a6f0></span><svg aria-hidden="true" data-v-40f0a6f0><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-40f0a6f0></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-10308273 data-v-60114dd7><!--[--><div class="container" data-v-60114dd7><p class="message" data-v-60114dd7>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><!----></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-BZRVOKAf.js" defer></script></body></html>